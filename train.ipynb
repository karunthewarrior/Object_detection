{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_path = './labels/'\n",
    "labels_list = [f.split('.')[0] for f in listdir(labels_path) if isfile(join(labels_path, f))]\n",
    "\n",
    "img_path = './image_data/'\n",
    "image_list = [f for f in listdir(img_path) if isfile(join(img_path, f)) if f.split('.')[0] in labels_list]\n",
    "\n",
    "x_train = np.zeros([len(image_list),3,480,640],dtype=np.uint8)\n",
    "y_train = np.zeros(([len(image_list),6,24,32]))\n",
    "\n",
    "for i in range(len(image_list)):  \n",
    "    input_image_name = image_list[i]\n",
    "    input_image = cv2.imread(img_path + input_image_name, 1).astype(np.float32)\n",
    "#     print input_image.shape\n",
    "    x_train[i,:,:,:] = input_image.transpose(2,0,1)\n",
    "    y_train[i,:,:,:] = (pickle.load(open(labels_path + input_image_name.split('.')[0] + '.p','rb'))).transpose(2,1,0)\n",
    "\n",
    "x_t_train = torch.from_numpy(x_train).float()\n",
    "y_t_train = torch.from_numpy(y_train)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(x_t_train, y_t_train)\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=4,\n",
    "                                      shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(detector, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2)  \n",
    "    \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(32, 32, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 64, 3, stride=1, padding=1),  \n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(4,stride=4)\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,(7, 9),stride=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64,10,1,stride=1),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    \n",
    "    def local_activation(self,x):\n",
    "#         print nn.LogSoftmax(dim=1)(x[:,0:2,:,:]).data.shape,nn.Sigmoid()(x[:,2:4,:,:]).data.shape,x[:,4:6,:,:].data.shape,nn.LogSoftmax(dim=1)(x[:,6:10,:,:]).data.shape,\"LOOK\"\n",
    "        o = torch.cat((nn.LogSoftmax(dim=1)(x[:,0:2,:,:]), \n",
    "                        nn.Sigmoid()(x[:,2:4,:,:]) ,\n",
    "                        x[:,4:6,:,:],\n",
    "                        nn.LogSoftmax(dim=1)(x[:,6:10,:,:]))\n",
    "                        ,1)\n",
    "        return o\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)  \n",
    "        x = self.conv3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.local_activation(x)\n",
    "        return x\n",
    "    \n",
    "model = detector()\n",
    "def compute_loss(output,label):\n",
    "    pred_loss = nn.NLLLoss()(output[:,0:2,:,:],label[:,0,:,:].long())\n",
    "    reg_loss = torch.sum(nn.MSELoss(reduce=False)(output[:,2:6,:,:],label[:,1:5,:,:].float()) * label[:,0:1,:,:].float())*0.5\n",
    "    class_loss = torch.sum(nn.NLLLoss(reduce=False)(output[:,6:10,:,:],label[:,5,:,:].long()) * label[:,0:1,:,:].float())*5\n",
    "    loss = pred_loss + reg_loss + class_loss\n",
    "    return loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,\n",
    "                             weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for data in trainloader:\n",
    "        img, label = data\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        loss = compute_loss(output, label)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}'\n",
    "      .format(epoch+1, 20, loss.data[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
